{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a2aaa1-f43a-4696-b733-10f70c19de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import (f_classif,SelectKBest)\n",
    "from scipy.cluster import hierarchy\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.insert(0, '/libraries')\n",
    "from libraries import Transformation_library\n",
    "import os\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b7198c-4c38-4470-9f11-84b2151a34d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###user-defined parameters\n",
    "is_balanced = 0 #do we want to use weights during classification?\n",
    "is_median = 0 #do we want to use median or mean when select optimal n (number of features)\n",
    "Dataset_N = 1 #number of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0cd094b-6644-4f38-9f00-faf9b03bb1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "###standard parameters\n",
    "level = 0.5 #auc when guess is random\n",
    "test = 0.2 #fraction for testing\n",
    "val = 0.2 #fraction for validation (from the rest part)\n",
    "ITER = 5 #number of iteration for random forest\n",
    "is_sparse = 1 #do we want to reduce sparsity?\n",
    "n_features = 20 #the maximum number of features we consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a72abf99-a24f-4043-b7aa-aa82d24138e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = int(1/test) #number of testing sets (5)\n",
    "val_sets = int(1/val) #number of validation sets (5)\n",
    "if Dataset_N==1:\n",
    "    binary = 11 #threshold for depression\n",
    "    sparsity_level = 0.5 #sparsity threshold to merge bacteria together\n",
    "if Dataset_N==2:\n",
    "    sparsity_level = 0.9 #sparsity threshold to merge bacteria together\n",
    "if is_balanced == 1:\n",
    "    class_weight = \"balanced\"\n",
    "else:\n",
    "    class_weight = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "654c5512-2549-41c9-818a-63bb272731e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###metadata\n",
    "if Dataset_N==1:\n",
    "    Metadata=pd.read_csv(\"BASIC_metadata_full.csv\",sep=',',low_memory=False) #read file with depression levels and ids of participants\n",
    "    Metadata.loc[Metadata.TimePoint==\"Trimester2\",\"TimePoint\"] = 0 #timepoits are 0,1,2\n",
    "    Metadata.loc[Metadata.TimePoint==\"Trimester3\",\"TimePoint\"] = 1\n",
    "    Metadata.loc[Metadata.TimePoint==\"PostpartumWeek6\",\"TimePoint\"] = 2\n",
    "    i = Metadata[Metadata.ReadsNumber<500000].index #remove insufficient reads\n",
    "    Metadata = Metadata.replace(Metadata.loc[i,'ReadsNumber'],np.nan)\n",
    "    EPDS = 2*np.ones_like(Metadata.EPDS) #2 is for missingness\n",
    "    EPDS[Metadata.EPDS>binary] = 1 #binary labels for depression\n",
    "    EPDS[Metadata.EPDS<=binary] = 0\n",
    "if Dataset_N==2:\n",
    "    Metadata=pd.read_csv(\"GMAP_metadata_public.csv\",sep=\",\",low_memory=False)\n",
    "    Metadata = Metadata.rename(columns={\"sample\": \"tp\"})\n",
    "    Metadata.loc[Metadata.tp==\"3_twomonth\",\"tp\"] = 0\n",
    "    Metadata.loc[Metadata.tp==\"4_fourmonth\",\"tp\"] = 1\n",
    "    Metadata.loc[Metadata.tp==\"5_sixmonth\",\"tp\"] = 2\n",
    "    time = [\".3.twomonth\", \".4.fourmonth\", \".5.sixmonth\"]\n",
    "    i = Metadata[pd.Series.isna(Metadata.case_id)].index #remove NaN values\n",
    "    Metadata = Metadata.drop(i)\n",
    "    AP = np.zeros_like(Metadata.case_id)\n",
    "    AP[Metadata.case_id.to_numpy()==\"AP Case\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f4164c5-b416-4267-a6c8-df5af7ccf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "###data\n",
    "profile =pd.read_csv(\"Species_Profile_full.csv\",sep=',',low_memory=False) #read file with compositional data\n",
    "species=profile.to_numpy()[:,1:]/100 #normilized to 1\n",
    "full_list_bacteria = list(profile.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dae9ae9c-e57d-4bf0-a044-1e7c77786d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test group 0\n",
      "val group 0\n",
      "d= 91\n",
      "delta 6e-07\n",
      "val group 1\n",
      "d= 93\n",
      "delta 6e-07\n",
      "val group 2\n",
      "d= 95\n",
      "delta 6e-07\n",
      "val group 3\n",
      "d= 91\n",
      "delta 6e-07\n",
      "val group 4\n",
      "d= 91\n",
      "delta 6e-07\n",
      "means [0.69615385 0.66923077 0.66076923 0.71076923 0.65076923 0.60538462\n",
      " 0.57615385 0.55692308 0.62692308 0.61538462 0.58230769 0.59846154\n",
      " 0.58538462 0.61692308 0.55538462 0.58538462 0.61       0.59692308\n",
      " 0.56692308 0.55846154]\n",
      "['x193' 'x235' 'x241' 'x245']\n",
      "importances [0.38231433 0.25438977 0.22612006 0.13717584]\n",
      "auc 0.6666666666666666\n",
      "importances [0.40263762 0.26702781 0.19781169 0.13252289]\n",
      "auc 0.6666666666666666\n",
      "importances [0.41208924 0.26514814 0.20496168 0.11780095]\n",
      "auc 0.6666666666666666\n",
      "importances [0.41482645 0.27872836 0.16848822 0.13795698]\n",
      "auc 0.6666666666666666\n",
      "importances [0.37457699 0.28631451 0.19491094 0.14419756]\n",
      "auc 0.6666666666666666\n",
      "feature_index 192\n",
      "2 Veillonella_parvula\n",
      "2 Haemophilus_parainfluenzae\n",
      "feature_index 234\n",
      "3 Ruthenibacterium_lactatiformans\n",
      "3 Dorea_formicigenerans\n",
      "feature_index 240\n",
      "3 Eggerthella_lenta\n",
      "3 Gordonibacter_pamelaeae\n",
      "feature_index 244\n",
      "1 Coprococcus_comes\n",
      "1 Dorea_longicatena\n",
      "test group 1\n",
      "val group 0\n",
      "d= 93\n",
      "delta 4.0000000000000003e-07\n",
      "val group 1\n",
      "d= 95\n",
      "delta 6e-07\n",
      "val group 2\n",
      "d= 98\n",
      "delta 4.0000000000000003e-07\n",
      "val group 3\n",
      "d= 95\n",
      "delta 4.0000000000000003e-07\n",
      "val group 4\n",
      "d= 92\n",
      "delta 4.0000000000000003e-07\n",
      "means [0.59615385 0.61307692 0.62307692 0.59230769 0.61307692 0.50230769\n",
      " 0.53153846 0.55307692 0.55615385 0.53307692 0.56076923 0.52923077\n",
      " 0.52384615 0.50692308 0.51       0.52538462 0.52846154 0.51846154\n",
      " 0.52       0.50692308]\n",
      "['x81' 'x178' 'x237']\n",
      "importances [0.26295012 0.39530401 0.34174587]\n",
      "auc 0.8020833333333333\n",
      "importances [0.29297737 0.36894069 0.33808194]\n",
      "auc 0.8333333333333333\n",
      "importances [0.2744091  0.34319823 0.38239267]\n",
      "auc 0.8020833333333333\n",
      "importances [0.26208773 0.40060515 0.33730712]\n",
      "auc 0.8333333333333333\n",
      "importances [0.28151308 0.38038128 0.33810564]\n",
      "auc 0.8020833333333333\n",
      "feature_index 80\n",
      "2 Akkermansia_muciniphila\n",
      "3 Akkermansia_muciniphila\n",
      "feature_index 177\n",
      "2 Veillonella_parvula\n",
      "2 Haemophilus_parainfluenzae\n",
      "feature_index 236\n",
      "3 Eggerthella_lenta\n",
      "3 Gordonibacter_pamelaeae\n",
      "test group 2\n",
      "val group 0\n",
      "d= 93\n",
      "delta 4.0000000000000003e-07\n",
      "val group 1\n",
      "d= 96\n",
      "delta 6e-07\n",
      "val group 2\n",
      "d= 98\n",
      "delta 4.0000000000000003e-07\n",
      "val group 3\n",
      "d= 98\n",
      "delta 4.0000000000000003e-07\n",
      "val group 4\n",
      "d= 95\n",
      "delta 4.0000000000000003e-07\n",
      "means [0.63846154 0.65076923 0.60153846 0.63692308 0.59461538 0.54769231\n",
      " 0.54230769 0.50076923 0.56230769 0.54230769 0.57230769 0.53230769\n",
      " 0.57230769 0.56230769 0.54230769 0.53230769 0.50230769 0.56230769\n",
      " 0.53230769 0.53230769]\n",
      "['x82' 'x185']\n",
      "importances [0.39844551 0.60155449]\n",
      "auc 0.6354166666666666\n",
      "importances [0.41236069 0.58763931]\n",
      "auc 0.6354166666666666\n",
      "importances [0.4028056 0.5971944]\n",
      "auc 0.6666666666666666\n",
      "importances [0.39362805 0.60637195]\n",
      "auc 0.6666666666666666\n",
      "importances [0.4066103 0.5933897]\n",
      "auc 0.6666666666666666\n",
      "feature_index 81\n",
      "3 Roseburia_intestinalis\n",
      "3 Eubacterium_sp_CAG_38\n",
      "feature_index 184\n",
      "2 Veillonella_parvula\n",
      "2 Haemophilus_parainfluenzae\n",
      "test group 3\n",
      "val group 0\n",
      "d= 93\n",
      "delta 4.0000000000000003e-07\n",
      "val group 1\n",
      "d= 95\n",
      "delta 6e-07\n",
      "val group 2\n",
      "d= 96\n",
      "delta 4.0000000000000003e-07\n",
      "val group 3\n",
      "d= 100\n",
      "delta 4.0000000000000003e-07\n",
      "val group 4\n",
      "d= 93\n",
      "delta 4.0000000000000003e-07\n",
      "means [0.53076923 0.59076923 0.57769231 0.54538462 0.63307692 0.59\n",
      " 0.61384615 0.59384615 0.59538462 0.58076923 0.55538462 0.54538462\n",
      " 0.57       0.55       0.55692308 0.51846154 0.52       0.52\n",
      " 0.52       0.49846154]\n",
      "['x92' 'x113' 'x203' 'x241' 'x251']\n",
      "importances [0.16634337 0.10938424 0.22509498 0.20252475 0.29665266]\n",
      "auc 0.8333333333333333\n",
      "importances [0.17884252 0.13196835 0.21636813 0.21989406 0.25292696]\n",
      "auc 0.8333333333333333\n",
      "importances [0.15763926 0.12447237 0.19874395 0.22665177 0.29249265]\n",
      "auc 0.6666666666666666\n",
      "importances [0.14832924 0.10727197 0.21618107 0.23253729 0.29568043]\n",
      "auc 0.7708333333333333\n",
      "importances [0.16123662 0.10175821 0.20810858 0.20068968 0.32820691]\n",
      "auc 0.8333333333333333\n",
      "feature_index 91\n",
      "1 Roseburia_faecis\n",
      "2 Roseburia_faecis\n",
      "feature_index 112\n",
      "1 Eubacterium_sp_CAG_38\n",
      "2 Eubacterium_sp_CAG_38\n",
      "feature_index 202\n",
      "2 Veillonella_parvula\n",
      "2 Haemophilus_parainfluenzae\n",
      "feature_index 240\n",
      "3 Ruthenibacterium_lactatiformans\n",
      "3 Dorea_formicigenerans\n",
      "feature_index 250\n",
      "3 Coprococcus_comes\n",
      "3 Dorea_longicatena\n",
      "test group 4\n",
      "val group 0\n",
      "d= 92\n",
      "delta 4.0000000000000003e-07\n",
      "val group 1\n",
      "d= 89\n",
      "delta 6e-07\n",
      "val group 2\n",
      "d= 92\n",
      "delta 4.0000000000000003e-07\n",
      "val group 3\n",
      "d= 97\n",
      "delta 4.0000000000000003e-07\n",
      "val group 4\n",
      "d= 94\n",
      "delta 4.0000000000000003e-07\n",
      "means [0.64615385 0.63769231 0.61       0.59230769 0.61846154 0.59846154\n",
      " 0.59692308 0.6        0.59076923 0.58769231 0.58538462 0.51692308\n",
      " 0.52846154 0.51846154 0.49846154 0.51384615 0.49384615 0.52\n",
      " 0.49384615 0.50846154]\n",
      "['x203']\n",
      "importances [1.]\n",
      "auc 0.40625\n",
      "importances [1.]\n",
      "auc 0.40625\n",
      "importances [1.]\n",
      "auc 0.40625\n",
      "importances [1.]\n",
      "auc 0.40625\n",
      "importances [1.]\n",
      "auc 0.40625\n"
     ]
    }
   ],
   "source": [
    "d_full = np.shape(species)[1]\n",
    "X_full, labels = [[] for _ in range(2)] #X is data in 3 rows, labels are EPDS at tp 2\n",
    "ID = profile.Sample_id.to_numpy() #id of a sample in profile\n",
    "Individual_ID = Metadata.Individual_ID #id of a person\n",
    "for i in np.unique(Individual_ID):\n",
    "    TP = Metadata.TimePoint[Individual_ID == i].to_numpy()\n",
    "    if sum((TP - np.array([0,1,2]))**2)!=0:\n",
    "        warnings.warn(\"TP are missing or in incorrect order\") #does not happen in the dataset we have\n",
    "    Outcomes = EPDS[Individual_ID == i]\n",
    "    if Outcomes[2]!=2:\n",
    "        Reads = Metadata.ReadsNumber[Individual_ID == i].to_numpy()\n",
    "        if 1-np.isnan(Reads[0]) and 1-np.isnan(Reads[1]) and 1-np.isnan(Reads[2]): #complete data\n",
    "            labels = np.append(labels, Outcomes[2])\n",
    "            Sample_ID = Metadata.Sample_ID[Individual_ID == i]  # id of a sample in metadata\n",
    "            Dataset_line = np.zeros((1,3,d_full))\n",
    "            for j in range(3):\n",
    "                tp_id = Sample_ID[TP == j].to_numpy()\n",
    "                Dataset_line[:, j, :] = species[np.where(ID == tp_id)[0], :]\n",
    "            X_full = Dataset_line if np.size(X_full) == 0 else np.concatenate([X_full, Dataset_line])\n",
    "X_f, X_t = X_full[labels == 0], X_full[labels == 1] #f = healthy, t = depressed\n",
    "size_f, size_t = np.shape(X_f)[0], np.shape(X_t)[0]\n",
    "test_f, test_t = int(size_f*test), int(size_t*test) #amounts to put to test set\n",
    "AUC_TEST, N_OPT, SENSITIVITY, SPECIFICITY = [[] for _ in range(4)]\n",
    "aucs_val = np.zeros((val_sets, ITER, n_features))\n",
    "for TS in range(test_sets): #test sets\n",
    "    print(\"test group\", TS)\n",
    "    test_f_range, test_t_range = range(TS * test_f, (TS + 1) * test_f), range(TS * test_t, (TS + 1) * test_t)\n",
    "    rest_f_range, rest_t_range = np.setdiff1d(range(size_f), test_f_range), np.setdiff1d(range(size_t), test_t_range)\n",
    "    X_f_test, X_t_test = X_f[test_f_range], X_t[test_t_range]\n",
    "    X_test = np.concatenate([X_f_test,X_t_test])\n",
    "    label_test = np.zeros(test_f + test_t)\n",
    "    label_test[test_f:] = 1\n",
    "    rest_f, rest_t = np.size(rest_f_range), np.size(rest_t_range)\n",
    "    val_f, val_t = int(rest_f * val), int(rest_t * val) #amounts to put to validation set\n",
    "    train_f, train_t = rest_f - val_f, rest_t - val_t #the rest of rest is for training set\n",
    "    for VS in range(val_sets): #val sets\n",
    "        print(\"val group\", VS)\n",
    "        val_f_range, val_t_range = rest_f_range[range(VS* val_f, (VS + 1) * val_f)], rest_t_range[range(VS* val_t, (VS + 1) * val_t)]\n",
    "        train_f_range, train_t_range = np.setdiff1d(rest_f_range, val_f_range), np.setdiff1d(rest_t_range, val_t_range)\n",
    "        X_f_val, X_t_val, X_f_train, X_t_train = X_f[val_f_range], X_t[val_t_range], X_f[train_f_range], X_t[train_t_range]\n",
    "        X_val, X_train = np.concatenate([X_f_val, X_t_val]), np.concatenate([X_f_train, X_t_train])\n",
    "        label_val, label_train = np.zeros(val_f + val_t), np.zeros(train_f + train_t)\n",
    "        label_val[val_f:], label_train[train_f:] = 1, 1\n",
    "        X_test_cut = X_test #no changes in data dimensionality if is_sparse = False\n",
    "        X = [X_train, X_val, X_test_cut]\n",
    "        bacteria_list = full_list_bacteria\n",
    "        if is_sparse == 1:\n",
    "            X_combine = X_train.reshape(-1,d_full)\n",
    "            sparsity = np.sum(X_combine == 0, axis=0) / np.shape(X_combine)[0]\n",
    "            for xi in range(len(X)):\n",
    "                other_species = np.sum(X[xi][:, :, sparsity >= sparsity_level], axis=-1).reshape(-1, 3, 1)\n",
    "                X[xi] = X[xi][:, :, sparsity < sparsity_level]\n",
    "                X[xi]= np.concatenate([X[xi], other_species], axis=-1)\n",
    "            bacteria_list = np.array(full_list_bacteria)[sparsity < sparsity_level]\n",
    "            bacteria_list = np.append(bacteria_list, \"other\")\n",
    "        d = np.shape(X[0])[2]\n",
    "        print(\"d=\", d)\n",
    "        dY = 3 * d\n",
    "        delta = np.min(X[0][X[0] > 0])\n",
    "        print(\"delta\", delta)  # the smallest element\n",
    "        for xi in range(len(X)):\n",
    "            X[xi] = (X[xi] + delta) / (1 + delta * d) #remove 0s\n",
    "        X_train, X_val, X_test_cut = X\n",
    "        X_train, X_val = np.reshape(X_train, (-1, dY)) / 3, np.reshape(X_val, (-1, dY)) / 3  # flatten inputs to one compositional vector\n",
    "        ### construct hierarchy tree\n",
    "        Y_train = Transformation_library.CLR(X_train)\n",
    "        Z = hierarchy.linkage(np.transpose(Y_train), method=\"ward\")\n",
    "        clustersize, clusters = Transformation_library.hierarchy_tree(Z, dY)\n",
    "        stats_train, stats_val = Transformation_library.data_transformation(X_train, Z, clustersize, clusters,dY), Transformation_library.data_transformation(X_val, Z, clustersize, clusters, dY)  ### construct features from hierarchy tree\n",
    "        n_features = np.min([n_features, np.shape(stats_train)[1]])\n",
    "        for j in range(n_features): #choose the best j + 1 features using filter method\n",
    "            sel = SelectKBest(f_classif, k=j + 1).fit(pd.DataFrame(stats_train), label_train)\n",
    "            Index = sel.get_support()\n",
    "            for seed in range(ITER): #classify by random forest with different random seeds\n",
    "                rf = RandomForestClassifier(random_state = seed, class_weight=class_weight).fit(stats_train[:,Index], label_train)\n",
    "                y_pred = rf.predict(stats_val[:,Index])\n",
    "                aucs_val[VS, seed, j] = roc_auc_score(label_val, y_pred)\n",
    "    if is_median == 1: #optimal number of features by median of mean\n",
    "        print(\"medians\", np.median(aucs_val, axis=(0, 1))) #average by validation sets and random seeds\n",
    "        n_opt = np.argmax(np.median(aucs_val, axis=(0, 1))) + 1\n",
    "    else:\n",
    "        print(\"means\", np.mean(aucs_val, axis = (0,1)))\n",
    "        n_opt=np.argmax(np.mean(aucs_val, axis = (0,1))) + 1\n",
    "    N_OPT =np.append(N_OPT, n_opt)\n",
    "    X_rest, label_rest = np.concatenate([X_train, X_val]), np.concatenate([label_train,label_val])#concatenate everything except testing set\n",
    "    X_test_cut = np.reshape(X_test_cut, (-1, dY)) / 3 #flatten testing set\n",
    "    Y_rest = Transformation_library.CLR(X_rest)\n",
    "    Z = hierarchy.linkage(np.transpose(Y_rest), method=\"ward\")\n",
    "    clustersize, clusters = Transformation_library.hierarchy_tree(Z, dY)\n",
    "    stats_rest, stats_test = Transformation_library.data_transformation(X_rest, Z, clustersize, clusters,dY), Transformation_library.data_transformation(X_test_cut, Z, clustersize, clusters, dY)  ### construct features from hierarchy tree\n",
    "    sel = SelectKBest(f_classif, k=n_opt).fit(pd.DataFrame(stats_rest), label_rest) #select optimal number of features\n",
    "    Index = sel.get_support()\n",
    "    feature_index = sel.get_feature_names_out()\n",
    "    print(feature_index)  # from features namas we can reconstruct what bacteria we use\n",
    "    feature_index = [int(s.replace('x', '')) - 1 for s in feature_index]\n",
    "    AUC = []\n",
    "    for seed in range(ITER):\n",
    "        rf = RandomForestClassifier(random_state = seed, class_weight=class_weight).fit(stats_rest[:, Index], label_rest)\n",
    "        print(\"importances\",rf.feature_importances_) #display importances of features\n",
    "        y_pred = rf.predict(stats_test[:, Index])\n",
    "        print(\"auc\", roc_auc_score(label_test, y_pred)) #display balanced accuracy\n",
    "        AUC = np.append(AUC, roc_auc_score(label_test, y_pred)) # balanced accuracy on testing set\n",
    "    if np.mean(AUC)>0.5:\n",
    "        for j in feature_index:\n",
    "            print(\"feature_index\", j)\n",
    "            i =  dY - 2 - j\n",
    "            cl0, cl1 = int(Z[i, 0]), int(Z[i, 1])\n",
    "            s0, s1 = int(clustersize[cl0]), int(clustersize[cl1])\n",
    "            cluster0, cluster1 = clusters[cl0, 0:s0].astype(int), clusters[cl1, 0:s1].astype(int)\n",
    "            cluster_all = np.concatenate([cluster0, cluster1])\n",
    "            for u in cluster_all:\n",
    "                quot, rem = divmod(u, d)\n",
    "                print(quot + 1, bacteria_list[rem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8ef45-9c93-4d1f-b2a2-f83dc3abed42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
